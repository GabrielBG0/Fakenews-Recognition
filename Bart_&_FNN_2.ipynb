{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bart_&_FNN 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqlTqzLZUAJ0WUeq0T3FwI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4fa3c202878745059fca73d2a7287938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9eed26b60c1842ffada2de7ea6092f86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd9d3dd134d042da9d8d2c69f3fbe38e",
              "IPY_MODEL_363a547697124e85a18eec9a3659ebda"
            ]
          }
        },
        "9eed26b60c1842ffada2de7ea6092f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd9d3dd134d042da9d8d2c69f3fbe38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8d808176c6a4c9f8ff45f3263483c2e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29f78fd615a84ce1bdf0f061f12141b0"
          }
        },
        "363a547697124e85a18eec9a3659ebda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a575da76b3f4b4a9ef9543abf9188f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 121kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ae70527e028411e8ef537488d5f511b"
          }
        },
        "a8d808176c6a4c9f8ff45f3263483c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29f78fd615a84ce1bdf0f061f12141b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a575da76b3f4b4a9ef9543abf9188f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ae70527e028411e8ef537488d5f511b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "189e97d01d204c40bdf26e903ba900eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45f6c90a9586497b82de2531199fb552",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3533e73e093e4399a2161f2345a662d7",
              "IPY_MODEL_600bd1773e674edf9e583b4515052b0c"
            ]
          }
        },
        "45f6c90a9586497b82de2531199fb552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3533e73e093e4399a2161f2345a662d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba69df10264c4015aedeeb5deec952a6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8fed4806a004b47bbd5440fb90e7b0d"
          }
        },
        "600bd1773e674edf9e583b4515052b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_632e5679a355421c80ab758880b5bd04",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 34.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_519d33b3677c4e01b08b6082edae1c7a"
          }
        },
        "ba69df10264c4015aedeeb5deec952a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8fed4806a004b47bbd5440fb90e7b0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "632e5679a355421c80ab758880b5bd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "519d33b3677c4e01b08b6082edae1c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21ea64189b6c4f5a9809b14a6eb4b1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_843c01108d854ef4b9386dfae8933bd0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8272d3c5a5c479ca39b8be765264294",
              "IPY_MODEL_67922b67ff5a47abb1fa1a766c70dbf5"
            ]
          }
        },
        "843c01108d854ef4b9386dfae8933bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8272d3c5a5c479ca39b8be765264294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2d57415421b4b62ae4d24e3945d1ac8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f525991177e1467993e1bb55c81e348c"
          }
        },
        "67922b67ff5a47abb1fa1a766c70dbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f8ce912fbf81489983beabdeba721e8f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.37MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2c9d40e6f6841b0b1d4cc02f6ce14ad"
          }
        },
        "b2d57415421b4b62ae4d24e3945d1ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f525991177e1467993e1bb55c81e348c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8ce912fbf81489983beabdeba721e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2c9d40e6f6841b0b1d4cc02f6ce14ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f2b5889c0244e649cfcbc35f0cda502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf217d99df1e4eca8144cf8b86d2ba74",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe51c6ffec18422c8c3f7a55931835c7",
              "IPY_MODEL_6b2c5626c6364dcaa3ebcf279da2fdfd"
            ]
          }
        },
        "cf217d99df1e4eca8144cf8b86d2ba74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe51c6ffec18422c8c3f7a55931835c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14c4cd506ed34f53a9d86ed5f2e23fb7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0067b0190ff340b4a68c15ead8778a17"
          }
        },
        "6b2c5626c6364dcaa3ebcf279da2fdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_054dbd633f1845b5af986f71ea370b49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:09&lt;00:00, 46.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_276ee0c0ea144910a1983186abd27ce2"
          }
        },
        "14c4cd506ed34f53a9d86ed5f2e23fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0067b0190ff340b4a68c15ead8778a17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "054dbd633f1845b5af986f71ea370b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "276ee0c0ea144910a1983186abd27ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a769a36b7dd4b658792a4ec42291924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98c313cc07ed49e3993782098540ca5a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d530b45d48384e3285b4cd669bfb3d0a",
              "IPY_MODEL_c6a8306cc4e6478db94e34168df5c9c1"
            ]
          }
        },
        "98c313cc07ed49e3993782098540ca5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d530b45d48384e3285b4cd669bfb3d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_882913655d1548e8b8f16bf3c1c1e646",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecf73db732734abf9af710712069ec5a"
          }
        },
        "c6a8306cc4e6478db94e34168df5c9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a8cad377eed4699905110dacc4bd2bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 50.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c6c314d98d947e5a9a40b60b463c21f"
          }
        },
        "882913655d1548e8b8f16bf3c1c1e646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecf73db732734abf9af710712069ec5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a8cad377eed4699905110dacc4bd2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c6c314d98d947e5a9a40b60b463c21f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielBG0/Fakenews-Recognition/blob/main/Bart_%26_FNN_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vshuUbgbOHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae71eae-297b-422b-90b9-0473f597ff8c"
      },
      "source": [
        "# Deleting default sample data folder\n",
        "!rm -rf /content/sample_data\n",
        "!unzip FakeNewsNet.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  FakeNewsNet.zip\n",
            "  inflating: FakeNewsNet/dict_documents.pkl  \n",
            "  inflating: FakeNewsNet/indexes.npy  \n",
            "  inflating: FakeNewsNet/labels.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFL0COcubk1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04aec320-d6a0-450b-9322-e72a56618bc8"
      },
      "source": [
        "# Install aditional librarys\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 9.6MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n",
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/d6/a3d2c55b940a7c556e88f5598b401990805fc0f0a28b2fc9870cf0b8c761/datasets-1.6.0-py3-none-any.whl (202kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 8.9MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: fsspec, huggingface-hub, xxhash, datasets\n",
            "Successfully installed datasets-1.6.0 fsspec-2021.4.0 huggingface-hub-0.0.8 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2sa_cIUGNzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a7debb9-c11a-46c1-d3fa-dadedfef38ef"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "documents = pickle.load(open(\"FakeNewsNet/dict_documents.pkl\", \"rb\"))\n",
        "indexes = np.load('FakeNewsNet/indexes.npy')\n",
        "lbls = np.load('FakeNewsNet/labels.npy')\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "for i in range(len(indexes)):\n",
        "    index = indexes[i]\n",
        "    texts.append(documents[index])\n",
        "    if lbls[i] == np.str_(\"-1\"):\n",
        "      labels.append(0)\n",
        "    else :\n",
        "      labels.append(1)\n",
        "\n",
        "print(\"lable 1: \" + str(labels[0]))\n",
        "print(\"text 1: \" + texts[0])\n",
        "print(type(labels[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lable 1: 0\n",
            "text 1: When I revealed in this column last year that Dame Helen Mirren was the new face of L’Oreal, I had hundreds of letters from readers, ecstatic that beauty giants are celebrating older women.  As these exclusive pictures show, from next week (February 5) Helen will be appearing in her first television advertising campaign for the company.  The 69-year-old actress will be seen championing the role of the older woman — and the candid, unretouched shots from the advert show that wrinkles, ageing hands and natural make-up can be beautiful.  Scroll down for video  Dame Helen Mirren photographed for the L'Oreal Paris age perfect campaign. In this shot Helen wears the Age Perfect day cream, the candid, unretouched shots are a refreshing change and champion the beauty of the older woman  I suspect this approach will sell more products than the glossier, airbrushed campaigns that many women feel don’t relate to them and their real lives.  During the filming of the advert, Dame Helen took time out to speak exclusively to us about what she really thinks about beauty — and reveals she doesn’t even like the word!  She told us: ‘I used to worry a lot more about my looks than I do now.  ‘I think the great advantage of getting older is that you let go of certain things. Having said that, I think all women worry to some degree — and I don’t think men are exempt.  ‘I don’t really like the word “beauty”. There are physically beautiful people in the world (David Beckham, for instance, is unbelievably beautiful), then there are other people that are not beautiful, but are very attractive because of their personality, energy, brilliance, genius: all kinds of things.  Helen (pictured for the L'Oreal campaign) says she used to worry about her looks but as she's aged she's learnt to let go of certain things  ‘So I have a resistance to the word “beautiful”. I wish we could find another word that takes it away from physical beauty and brings it more into the world of true attractiveness.’  Dame Helen also told of her shock at being asked to be the face of L’Oreal. ‘I was surprised — but flattered as I am a fan of the brand and its products.  ‘I love make-up. I’m often seen prowling the aisles of various chemists all over the world looking for a new lipstick or a new mascara, so to become a spokesperson for a major cosmetics firm is very exciting.  ‘I think L’Oreal’s slogan “Because I’m Worth It” really strikes a chord with women. Self-esteem is such a hugely important thing and it’s so difficult for all of us.  Dame Helen's much admired hair colour is now maintained by L'Oreal Excellence Age Perfect  ‘Everybody has moments of massive insecurity and I think anything that makes you feel more confident and more secure in yourself is a great thing. It’s tough for a lot of women with busy schedules or limited resources: they are incredibly busy and have difficult lives. To stop for a few seconds to say: “You know what, I can sit down, have a breather, a cup of tea or a bath and think “Yes, I’m worth it, my life is worth it” is so important.  ‘People say to me “Oh, you’re so self-confident” but I am not naturally self-confident, I just have had to be in my work and my life. If it’s a problem, it’s my problem — I’ve got to deal with it.’  It’s this refreshing honesty that makes Helen the perfect figurehead for older women. So was there an age at which she started to feel differently about the way she looked?  ‘My whole life has been slightly different from most people’s in the sense that I’ve always had to look at images of myself from when I was 21 years old,’ she said.  ‘I’ve either been in front of a camera or in the theatre, being photographed, having my picture in the paper, so I’ve grown up with what I look like and ageing has never sort of come as a shock.  ‘I’m not obsessive when it comes to looking after my skin. I have always used moisturiser at night and in the morning — it makes me feel better and to me that’s what I want from it.  ‘It doesn’t have to make me look ten years younger: it’s all about how it makes me feel better that day.  ‘My biggest beauty advice is just to make sure you clean your skin really well and don’t smoke. I also have to have my eight hours of sleep a night.’  While her new role as an ambassador for the beauty brand hasn’t changed Helen’s skincare regime, what has changed is her hair.  Dame Helen is pictured here at the Golden Globe awards two weeks ago, accompanying her stylist dress with a slash of bold red lipstick  For the initial print campaign, she was given a stylish crop, and her much-admired bright blonde is now maintained using L’Oreal’s new Excellence Age Perfect hair colour.  ‘I have very fine hair so I’ve always been quite careful not to overtreat it. I don’t normally colour or dye it, I like it to grow naturally, but this dye is fantastic. It really does what it says on the box, allows my hair to grow out naturally and is also very easy to use. It’s my new favourite product.  ‘Yes, I know it sounds like I’m saying it because of the advertising, but it’s true! The brilliant thing is that it has layers of colour, it’s not one colour that you then need to add highlights on top of.’  So what hair advice would she give to somebody who, like her, is in their 60s?  ‘Be bold! Be bold with your cut, really look what young people are doing and copy them — don’t copy what old people are doing.  Seen here last year, Helen is clearly a fan of a statement lip. She says her advice to women out there is to look at what's happening now style-wise and 'go with the flow'  ‘I loved it when I dyed my hair pink. A lot of women get stuck at what they are good at and what they did between the ages of 18 and 28 and they never have the courage to change that.  ‘You see women from the Sixties still with their beehives and now they’re in their 70s. You see women from the Eighties who still have those Eighties hair-dos. My advice is to look at what’s happening now and go with the flow — don’t do what you did when you were 24.  ‘Some people have a classic haircut and it works for them and that’s great, but it’s much better to accept how you look now and then be modern.’\n",
            "<class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWfap6BnZLOQ",
        "outputId": "091f1351-25b7-4821-ee1e-a5de9c0488fc"
      },
      "source": [
        "for text in texts:\n",
        "  if len(text.split(' ')) > 512:\n",
        "    print(\"there are too long texts! truncate then\")\n",
        "    break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are too long texts! truncate then\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrknzXnzsC0P"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import (TensorDataset, DataLoader,\n",
        "                              RandomSampler, SequentialSampler)\n",
        "\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from distutils.version import LooseVersion as LV\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import io, sys, os, datetime\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua2efKxpsHyJ"
      },
      "source": [
        "if 'DATADIR' in os.environ:\n",
        "    DATADIR = os.environ['DATADIR']\n",
        "else:\n",
        "    DATADIR = \"/content/\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvSJoZ6OsKtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e5ca05-5cab-43eb-d5c1-586696ff81d4"
      },
      "source": [
        "# Split the data into a training set and a test set using\n",
        "# scikit-learn's train_test_split().\n",
        "\n",
        "TEST_SET = 4000\n",
        "\n",
        "(sentences_train, sentences_test,\n",
        " labels_train, labels_test) = train_test_split(texts, labels,\n",
        "                                               test_size=TEST_SET,\n",
        "                                               shuffle=True, random_state=42)\n",
        "\n",
        "print('Length of training texts:', len(sentences_train))\n",
        "print('Length of training labels:', len(labels_train))\n",
        "print('Length of test texts:', len(sentences_test))\n",
        "print('Length of test labels:', len(labels_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of training texts: 3003\n",
            "Length of training labels: 3003\n",
            "Length of test texts: 4000\n",
            "Length of test labels: 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RJY8VdCsNkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4e9395-58d8-4aa4-cf41-f34a814ec924"
      },
      "source": [
        "# The token [CLS] is a special token required by BERT at the beginning\n",
        "# of the sentence.\n",
        "\n",
        "sentences_train = [\"[CLS] \" + s for s in sentences_train]\n",
        "sentences_test = [\"[CLS] \" + s for s in sentences_test]\n",
        "\n",
        "print (\"The first training sentence:\")\n",
        "print(sentences_train[0], 'LABEL:', labels_train[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The first training sentence:\n",
            "[CLS] The Real Housewives of Atlanta family just welcomed a new member. RHOA rookie Eva Marcille gave birth to a baby boy, Michael Todd Sterling, Jr., on Friday, April 13, she shared on Instagram.  Eva's son was born at 5:59 p.m. on Friday at 7 pounds, 3 ounces and 19-and-a-half inches long, according to a post on Instagram that showed a photo of little Michael's footprints. Eva captioned the photo, \"All praises be to God!\"  The baby boy is Eva's first child with her fiancé, Michael Todd Sterling, an attorney and former candidate for mayor of Atlanta, and their child is named after Sterling. She also has a 4-year-old daughter, Marley Rae, from a previous relationship with musician Kevin McCall.  🤱🏽 All praises be to God! A post shared by Eva Marcille (@evamarcille) on Apr 13, 2018 at 5:57pm PDT  It appears that Eva has been in the hospital since Thursday, April 12, according to photos she posted on Instagram.  Still at it😳 Come on Mikey🤰🏽 A post shared by Eva Marcille (@evamarcille) on Apr 13, 2018 at 11:40am PDT  Eva first announced the happy news of her second pregnancy during an interview with PEOPLE in November 2017. It wasn't long after that when Eva shared the news on Christmas that she and Michael Sr. had gotten engaged.  Eva previously opened up to The Daily Dish about her pregnancy in March, exclaiming that she was \"super, duper excited\" to welcome her baby boy. However, she wasn't so sure if she was ready to have the experience of going into labor again. \"My daughter was 31 hours in labor, like full pain, back labor, the whole nine. And for some reason, I kind of forgot about that, and now I'm remembering all of that, so there's just a little bit of anxiety. Not much, just a little bit,\" she said. \"I feel like I'm as ready as I'm gonna be. There's not much I can do. I'm just gonna bite my teeth, grin and bear it, and Dad will be there feeding me ice chips. So hopefully it'll all work out.\"  But Eva said that she's really been \"a lot less antsy\" during her second pregnancy. \"The biggest thing that I learned from being pregnant with Marley and now being pregnant with Mikey is [to] stop worrying. I remember being pregnant with Marley, and every single thing I'm like, 'What is she doing in there? Was that an elbow? Was that a knee? Is she kicking? Is she trying to get out?' I didn't know what was what. I was wondering if I was drinking something and if it was too cold for her or too hot. I was thinking way too much,\" she shared. \"Now, I'm like, sit back, I eat whatever I want to. I'm like, 'It's cold, huh? Feels good doesn't it?' I just take it in stride. It's a lot different. I'm a lot less antsy.\"  Eva also shared that Michael Sr. was \"super excited\" to experience the birth of his son. But perhaps no one in Eva's family was looking forward to the arrival of little Mikey as much as her daughter, Marley, who has been carrying a crocheted blanket around the house as if it were her little brother. \"Marley is so excited about being a big sister,\" Eva gushed. \"We put together our fun new fancy stroller, and it's up in the house. So Marley puts the blanket in the stroller, and she goes around the house with it. And she's like, 'Mom, we'll be back. I'm taking the baby to the beach.' She goes around through the living room, through the dining room with the stroller. It's the cutest thing ever. She's, like, really ready.\"  Eva and Michael Sr. threw a prince-themed baby shower in Atlanta in honor of their son in March. The America's Next Top Model Cycle 3 winner also proved that she looks just as fierce pregnant during a gorgeous maternity shoot, which she shared photos from earlier this month.  Check out more Eva, below. LABEL: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMta6VeMsPaz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "4fa3c202878745059fca73d2a7287938",
            "9eed26b60c1842ffada2de7ea6092f86",
            "bd9d3dd134d042da9d8d2c69f3fbe38e",
            "363a547697124e85a18eec9a3659ebda",
            "a8d808176c6a4c9f8ff45f3263483c2e",
            "29f78fd615a84ce1bdf0f061f12141b0",
            "1a575da76b3f4b4a9ef9543abf9188f3",
            "9ae70527e028411e8ef537488d5f511b",
            "189e97d01d204c40bdf26e903ba900eb",
            "45f6c90a9586497b82de2531199fb552",
            "3533e73e093e4399a2161f2345a662d7",
            "600bd1773e674edf9e583b4515052b0c",
            "ba69df10264c4015aedeeb5deec952a6",
            "c8fed4806a004b47bbd5440fb90e7b0d",
            "632e5679a355421c80ab758880b5bd04",
            "519d33b3677c4e01b08b6082edae1c7a",
            "21ea64189b6c4f5a9809b14a6eb4b1f1",
            "843c01108d854ef4b9386dfae8933bd0",
            "b8272d3c5a5c479ca39b8be765264294",
            "67922b67ff5a47abb1fa1a766c70dbf5",
            "b2d57415421b4b62ae4d24e3945d1ac8",
            "f525991177e1467993e1bb55c81e348c",
            "f8ce912fbf81489983beabdeba721e8f",
            "f2c9d40e6f6841b0b1d4cc02f6ce14ad"
          ]
        },
        "outputId": "7927e28b-c368-4e31-d8ec-90d8052b66f1"
      },
      "source": [
        "# Next we specify the pre-trained BERT model we are going to use. The\n",
        "# model `\"bert-base-uncased\"` is the lowercased \"base\" model\n",
        "# (12-layer, 768-hidden, 12-heads, 110M parameters).\n",
        "#\n",
        "# We load the used vocabulary from the BERT model, and use the BERT\n",
        "# tokenizer to convert the sentences into tokens that match the data\n",
        "# the BERT model was trained on.\n",
        "\n",
        "print('Initializing BertTokenizer')\n",
        "\n",
        "BERTMODEL='bert-base-uncased'\n",
        "CACHE_DIR=os.path.join(DATADIR, 'transformers-cache')\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(BERTMODEL, cache_dir=CACHE_DIR,\n",
        "                                          do_lower_case=True)\n",
        "\n",
        "tokenized_train = [tokenizer.tokenize(s) for s in sentences_train]\n",
        "tokenized_test  = [tokenizer.tokenize(s) for s in sentences_test]\n",
        "\n",
        "print (\"The full tokenized first training sentence:\")\n",
        "print (tokenized_train[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing BertTokenizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fa3c202878745059fca73d2a7287938",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "189e97d01d204c40bdf26e903ba900eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21ea64189b6c4f5a9809b14a6eb4b1f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The full tokenized first training sentence:\n",
            "['[CLS]', 'the', 'real', 'house', '##wives', 'of', 'atlanta', 'family', 'just', 'welcomed', 'a', 'new', 'member', '.', 'r', '##ho', '##a', 'rookie', 'eva', 'marc', '##ille', 'gave', 'birth', 'to', 'a', 'baby', 'boy', ',', 'michael', 'todd', 'sterling', ',', 'jr', '.', ',', 'on', 'friday', ',', 'april', '13', ',', 'she', 'shared', 'on', 'ins', '##tagram', '.', 'eva', \"'\", 's', 'son', 'was', 'born', 'at', '5', ':', '59', 'p', '.', 'm', '.', 'on', 'friday', 'at', '7', 'pounds', ',', '3', 'ounce', '##s', 'and', '19', '-', 'and', '-', 'a', '-', 'half', 'inches', 'long', ',', 'according', 'to', 'a', 'post', 'on', 'ins', '##tagram', 'that', 'showed', 'a', 'photo', 'of', 'little', 'michael', \"'\", 's', 'footprints', '.', 'eva', 'capt', '##ioned', 'the', 'photo', ',', '\"', 'all', 'praises', 'be', 'to', 'god', '!', '\"', 'the', 'baby', 'boy', 'is', 'eva', \"'\", 's', 'first', 'child', 'with', 'her', 'fiance', ',', 'michael', 'todd', 'sterling', ',', 'an', 'attorney', 'and', 'former', 'candidate', 'for', 'mayor', 'of', 'atlanta', ',', 'and', 'their', 'child', 'is', 'named', 'after', 'sterling', '.', 'she', 'also', 'has', 'a', '4', '-', 'year', '-', 'old', 'daughter', ',', 'marley', 'rae', ',', 'from', 'a', 'previous', 'relationship', 'with', 'musician', 'kevin', 'mccall', '.', '[UNK]', 'all', 'praises', 'be', 'to', 'god', '!', 'a', 'post', 'shared', 'by', 'eva', 'marc', '##ille', '(', '@', 'eva', '##mar', '##ci', '##lle', ')', 'on', 'apr', '13', ',', '2018', 'at', '5', ':', '57', '##pm', 'pd', '##t', 'it', 'appears', 'that', 'eva', 'has', 'been', 'in', 'the', 'hospital', 'since', 'thursday', ',', 'april', '12', ',', 'according', 'to', 'photos', 'she', 'posted', 'on', 'ins', '##tagram', '.', 'still', 'at', '[UNK]', 'come', 'on', '[UNK]', 'a', 'post', 'shared', 'by', 'eva', 'marc', '##ille', '(', '@', 'eva', '##mar', '##ci', '##lle', ')', 'on', 'apr', '13', ',', '2018', 'at', '11', ':', '40', '##am', 'pd', '##t', 'eva', 'first', 'announced', 'the', 'happy', 'news', 'of', 'her', 'second', 'pregnancy', 'during', 'an', 'interview', 'with', 'people', 'in', 'november', '2017', '.', 'it', 'wasn', \"'\", 't', 'long', 'after', 'that', 'when', 'eva', 'shared', 'the', 'news', 'on', 'christmas', 'that', 'she', 'and', 'michael', 'sr', '.', 'had', 'gotten', 'engaged', '.', 'eva', 'previously', 'opened', 'up', 'to', 'the', 'daily', 'dish', 'about', 'her', 'pregnancy', 'in', 'march', ',', 'ex', '##claiming', 'that', 'she', 'was', '\"', 'super', ',', 'du', '##per', 'excited', '\"', 'to', 'welcome', 'her', 'baby', 'boy', '.', 'however', ',', 'she', 'wasn', \"'\", 't', 'so', 'sure', 'if', 'she', 'was', 'ready', 'to', 'have', 'the', 'experience', 'of', 'going', 'into', 'labor', 'again', '.', '\"', 'my', 'daughter', 'was', '31', 'hours', 'in', 'labor', ',', 'like', 'full', 'pain', ',', 'back', 'labor', ',', 'the', 'whole', 'nine', '.', 'and', 'for', 'some', 'reason', ',', 'i', 'kind', 'of', 'forgot', 'about', 'that', ',', 'and', 'now', 'i', \"'\", 'm', 'remembering', 'all', 'of', 'that', ',', 'so', 'there', \"'\", 's', 'just', 'a', 'little', 'bit', 'of', 'anxiety', '.', 'not', 'much', ',', 'just', 'a', 'little', 'bit', ',', '\"', 'she', 'said', '.', '\"', 'i', 'feel', 'like', 'i', \"'\", 'm', 'as', 'ready', 'as', 'i', \"'\", 'm', 'gonna', 'be', '.', 'there', \"'\", 's', 'not', 'much', 'i', 'can', 'do', '.', 'i', \"'\", 'm', 'just', 'gonna', 'bite', 'my', 'teeth', ',', 'grin', 'and', 'bear', 'it', ',', 'and', 'dad', 'will', 'be', 'there', 'feeding', 'me', 'ice', 'chips', '.', 'so', 'hopefully', 'it', \"'\", 'll', 'all', 'work', 'out', '.', '\"', 'but', 'eva', 'said', 'that', 'she', \"'\", 's', 'really', 'been', '\"', 'a', 'lot', 'less', 'ants', '##y', '\"', 'during', 'her', 'second', 'pregnancy', '.', '\"', 'the', 'biggest', 'thing', 'that', 'i', 'learned', 'from', 'being', 'pregnant', 'with', 'marley', 'and', 'now', 'being', 'pregnant', 'with', 'mikey', 'is', '[', 'to', ']', 'stop', 'worrying', '.', 'i', 'remember', 'being', 'pregnant', 'with', 'marley', ',', 'and', 'every', 'single', 'thing', 'i', \"'\", 'm', 'like', ',', \"'\", 'what', 'is', 'she', 'doing', 'in', 'there', '?', 'was', 'that', 'an', 'elbow', '?', 'was', 'that', 'a', 'knee', '?', 'is', 'she', 'kicking', '?', 'is', 'she', 'trying', 'to', 'get', 'out', '?', \"'\", 'i', 'didn', \"'\", 't', 'know', 'what', 'was', 'what', '.', 'i', 'was', 'wondering', 'if', 'i', 'was', 'drinking', 'something', 'and', 'if', 'it', 'was', 'too', 'cold', 'for', 'her', 'or', 'too', 'hot', '.', 'i', 'was', 'thinking', 'way', 'too', 'much', ',', '\"', 'she', 'shared', '.', '\"', 'now', ',', 'i', \"'\", 'm', 'like', ',', 'sit', 'back', ',', 'i', 'eat', 'whatever', 'i', 'want', 'to', '.', 'i', \"'\", 'm', 'like', ',', \"'\", 'it', \"'\", 's', 'cold', ',', 'huh', '?', 'feels', 'good', 'doesn', \"'\", 't', 'it', '?', \"'\", 'i', 'just', 'take', 'it', 'in', 'stride', '.', 'it', \"'\", 's', 'a', 'lot', 'different', '.', 'i', \"'\", 'm', 'a', 'lot', 'less', 'ants', '##y', '.', '\"', 'eva', 'also', 'shared', 'that', 'michael', 'sr', '.', 'was', '\"', 'super', 'excited', '\"', 'to', 'experience', 'the', 'birth', 'of', 'his', 'son', '.', 'but', 'perhaps', 'no', 'one', 'in', 'eva', \"'\", 's', 'family', 'was', 'looking', 'forward', 'to', 'the', 'arrival', 'of', 'little', 'mikey', 'as', 'much', 'as', 'her', 'daughter', ',', 'marley', ',', 'who', 'has', 'been', 'carrying', 'a', 'cr', '##oche', '##ted', 'blanket', 'around', 'the', 'house', 'as', 'if', 'it', 'were', 'her', 'little', 'brother', '.', '\"', 'marley', 'is', 'so', 'excited', 'about', 'being', 'a', 'big', 'sister', ',', '\"', 'eva', 'gus', '##hed', '.', '\"', 'we', 'put', 'together', 'our', 'fun', 'new', 'fancy', 'stroll', '##er', ',', 'and', 'it', \"'\", 's', 'up', 'in', 'the', 'house', '.', 'so', 'marley', 'puts', 'the', 'blanket', 'in', 'the', 'stroll', '##er', ',', 'and', 'she', 'goes', 'around', 'the', 'house', 'with', 'it', '.', 'and', 'she', \"'\", 's', 'like', ',', \"'\", 'mom', ',', 'we', \"'\", 'll', 'be', 'back', '.', 'i', \"'\", 'm', 'taking', 'the', 'baby', 'to', 'the', 'beach', '.', \"'\", 'she', 'goes', 'around', 'through', 'the', 'living', 'room', ',', 'through', 'the', 'dining', 'room', 'with', 'the', 'stroll', '##er', '.', 'it', \"'\", 's', 'the', 'cute', '##st', 'thing', 'ever', '.', 'she', \"'\", 's', ',', 'like', ',', 'really', 'ready', '.', '\"', 'eva', 'and', 'michael', 'sr', '.', 'threw', 'a', 'prince', '-', 'themed', 'baby', 'shower', 'in', 'atlanta', 'in', 'honor', 'of', 'their', 'son', 'in', 'march', '.', 'the', 'america', \"'\", 's', 'next', 'top', 'model', 'cycle', '3', 'winner', 'also', 'proved', 'that', 'she', 'looks', 'just', 'as', 'fierce', 'pregnant', 'during', 'a', 'gorgeous', 'maternity', 'shoot', ',', 'which', 'she', 'shared', 'photos', 'from', 'earlier', 'this', 'month', '.', 'check', 'out', 'more', 'eva', ',', 'below', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vv7nwxpsR_U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8223de51-dc9e-42fa-a7ee-2198d92eb628"
      },
      "source": [
        "# Now we set the maximum sequence lengths for our training and test\n",
        "# sentences as `MAX_LEN_TRAIN` and `MAX_LEN_TEST`. The maximum length\n",
        "# supported by the used BERT model is 512.\n",
        "#\n",
        "# The token `[SEP]` is another special token required by BERT at the\n",
        "# end of the sentence.\n",
        "\n",
        "MAX_LEN_TRAIN, MAX_LEN_TEST = 128, 512\n",
        "\n",
        "tokenized_train = [t[:(MAX_LEN_TRAIN-1)]+['SEP'] for t in tokenized_train]\n",
        "tokenized_test  = [t[:(MAX_LEN_TEST-1)]+['SEP'] for t in tokenized_test]\n",
        "\n",
        "print (\"The truncated tokenized first training sentence:\")\n",
        "print (tokenized_train[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The truncated tokenized first training sentence:\n",
            "['[CLS]', 'the', 'real', 'house', '##wives', 'of', 'atlanta', 'family', 'just', 'welcomed', 'a', 'new', 'member', '.', 'r', '##ho', '##a', 'rookie', 'eva', 'marc', '##ille', 'gave', 'birth', 'to', 'a', 'baby', 'boy', ',', 'michael', 'todd', 'sterling', ',', 'jr', '.', ',', 'on', 'friday', ',', 'april', '13', ',', 'she', 'shared', 'on', 'ins', '##tagram', '.', 'eva', \"'\", 's', 'son', 'was', 'born', 'at', '5', ':', '59', 'p', '.', 'm', '.', 'on', 'friday', 'at', '7', 'pounds', ',', '3', 'ounce', '##s', 'and', '19', '-', 'and', '-', 'a', '-', 'half', 'inches', 'long', ',', 'according', 'to', 'a', 'post', 'on', 'ins', '##tagram', 'that', 'showed', 'a', 'photo', 'of', 'little', 'michael', \"'\", 's', 'footprints', '.', 'eva', 'capt', '##ioned', 'the', 'photo', ',', '\"', 'all', 'praises', 'be', 'to', 'god', '!', '\"', 'the', 'baby', 'boy', 'is', 'eva', \"'\", 's', 'first', 'child', 'with', 'her', 'fiance', ',', 'michael', 'SEP']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEfpj_lfsT0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a2b0c67-120a-40f7-aa56-fdb1df1d6dee"
      },
      "source": [
        "# Next we use the BERT tokenizer to convert each token into an integer\n",
        "# index in the BERT vocabulary. We also pad any shorter sequences to\n",
        "# `MAX_LEN_TRAIN` or `MAX_LEN_TEST` indices with trailing zeros.\n",
        "\n",
        "ids_train = [tokenizer.convert_tokens_to_ids(t) for t in tokenized_train]\n",
        "ids_train = np.array([np.pad(i, (0, MAX_LEN_TRAIN-len(i)),\n",
        "                             mode='constant') for i in ids_train])\n",
        "\n",
        "ids_test = [tokenizer.convert_tokens_to_ids(t) for t in tokenized_test]\n",
        "ids_test = np.array([np.pad(i, (0, MAX_LEN_TEST-len(i)),\n",
        "                            mode='constant') for i in ids_test])\n",
        "\n",
        "print (\"The indices of the first training sentence:\")\n",
        "print (ids_train[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The indices of the first training sentence:\n",
            "[  101  1996  2613  2160 23744  1997  5865  2155  2074 10979  1037  2047\n",
            "  2266  1012  1054  6806  2050  8305  9345  7871 10484  2435  4182  2000\n",
            "  1037  3336  2879  1010  2745  6927 10933  1010  3781  1012  1010  2006\n",
            "  5958  1010  2258  2410  1010  2016  4207  2006 16021 23091  1012  9345\n",
            "  1005  1055  2365  2001  2141  2012  1019  1024  5354  1052  1012  1049\n",
            "  1012  2006  5958  2012  1021  7038  1010  1017 19471  2015  1998  2539\n",
            "  1011  1998  1011  1037  1011  2431  5282  2146  1010  2429  2000  1037\n",
            "  2695  2006 16021 23091  2008  3662  1037  6302  1997  2210  2745  1005\n",
            "  1055 24629  1012  9345 14408 19798  1996  6302  1010  1000  2035 27128\n",
            "  2022  2000  2643   999  1000  1996  3336  2879  2003  9345  1005  1055\n",
            "  2034  2775  2007  2014 19154  1010  2745   100]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS0O_TzBsVh8"
      },
      "source": [
        "# BERT also requires *attention masks*, with 1 for each real token in\n",
        "# the sequences and 0 for the padding:\n",
        "\n",
        "amasks_train, amasks_test = [], []\n",
        "\n",
        "for seq in ids_train:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  amasks_train.append(seq_mask)\n",
        "\n",
        "for seq in ids_test:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  amasks_test.append(seq_mask)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ5-BnPEsXQW"
      },
      "source": [
        "# We use again scikit-learn's train_test_split to use 10% of our\n",
        "# training data as a validation set, and then convert all data into\n",
        "# torch.tensors.\n",
        "\n",
        "(train_inputs, validation_inputs,\n",
        " train_labels, validation_labels) = train_test_split(ids_train, labels_train,\n",
        "                                                     random_state=42,\n",
        "                                                     test_size=0.1)\n",
        "(train_masks, validation_masks,\n",
        " _, _) = train_test_split(amasks_train, ids_train,\n",
        "                          random_state=42, test_size=0.1)\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks  = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks  = torch.tensor(validation_masks)\n",
        "test_inputs = torch.tensor(ids_test)\n",
        "test_labels = torch.tensor(labels_test)\n",
        "test_masks  = torch.tensor(amasks_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv6WJqDjsY3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf2d058-3165-4fd7-a785-6337a62de3ea"
      },
      "source": [
        "# Next we create PyTorch DataLoaders for all data sets.\n",
        "#\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a\n",
        "# batch size of 16 or 32.\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "print('Train: ', end=\"\")\n",
        "train_data = TensorDataset(train_inputs, train_masks,\n",
        "                           train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler,\n",
        "                              batch_size=BATCH_SIZE)\n",
        "print(len(train_data), 'messages')\n",
        "\n",
        "print('Validation: ', end=\"\")\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks,\n",
        "                                validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data,\n",
        "                                   sampler=validation_sampler,\n",
        "                                   batch_size=BATCH_SIZE)\n",
        "print(len(validation_data), 'messages')\n",
        "\n",
        "print('Test: ', end=\"\")\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler,\n",
        "                             batch_size=BATCH_SIZE)\n",
        "print(len(test_data), 'messages')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 2702 messages\n",
            "Validation: 301 messages\n",
            "Test: 4000 messages\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXgIadwusbF4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9f2b5889c0244e649cfcbc35f0cda502",
            "cf217d99df1e4eca8144cf8b86d2ba74",
            "fe51c6ffec18422c8c3f7a55931835c7",
            "6b2c5626c6364dcaa3ebcf279da2fdfd",
            "14c4cd506ed34f53a9d86ed5f2e23fb7",
            "0067b0190ff340b4a68c15ead8778a17",
            "054dbd633f1845b5af986f71ea370b49",
            "276ee0c0ea144910a1983186abd27ce2",
            "1a769a36b7dd4b658792a4ec42291924",
            "98c313cc07ed49e3993782098540ca5a",
            "d530b45d48384e3285b4cd669bfb3d0a",
            "c6a8306cc4e6478db94e34168df5c9c1",
            "882913655d1548e8b8f16bf3c1c1e646",
            "ecf73db732734abf9af710712069ec5a",
            "1a8cad377eed4699905110dacc4bd2bf",
            "4c6c314d98d947e5a9a40b60b463c21f"
          ]
        },
        "outputId": "c7dbba31-ab72-477c-8cad-f8f9feca6ab8"
      },
      "source": [
        "# ## BERT model initialization\n",
        "#\n",
        "# We now load a pretrained BERT model with a single linear\n",
        "# classification layer added on top.\n",
        "\n",
        "print('Initializing BertForSequenceClassification')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(BERTMODEL,\n",
        "                                                      cache_dir=CACHE_DIR,\n",
        "                                                      num_labels=20)\n",
        "model.cuda()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing BertForSequenceClassification\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f2b5889c0244e649cfcbc35f0cda502",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a769a36b7dd4b658792a4ec42291924",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwIWqs3JsdLK"
      },
      "source": [
        "# We set the remaining hyperparameters needed for fine-tuning the\n",
        "# pretrained model:\n",
        "#   * EPOCHS: the number of training epochs in fine-tuning\n",
        "#     (recommended values between 2 and 4)\n",
        "#   * WEIGHT_DECAY: weight decay for the Adam optimizer\n",
        "#   * LR: learning rate for the Adam optimizer (2e-5 to 5e-5 recommended)\n",
        "#   * WARMUP_STEPS: number of warmup steps to (linearly) reach the set\n",
        "#     learning rate\n",
        "#\n",
        "# We also need to grab the training parameters from the pretrained model.\n",
        "\n",
        "EPOCHS = 16\n",
        "WEIGHT_DECAY = 0.01\n",
        "LR = 2e-5\n",
        "WARMUP_STEPS =int(0.2*len(train_dataloader))\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters()\n",
        "                if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': WEIGHT_DECAY},\n",
        "    {'params': [p for n, p in model.named_parameters()\n",
        "                if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=LR, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=WARMUP_STEPS,\n",
        "                                            num_training_steps=len(train_dataloader)*EPOCHS)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0oxg9aImm8B",
        "outputId": "6ae3c795-701b-42ee-d637-1dbcbde5df95"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNZ6CMLFsfvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e648826c-b153-4031-e6a7-cf76e8f1339b"
      },
      "source": [
        "# ## Learning\n",
        "#\n",
        "# Let's now define functions to train() and evaluate() the model:\n",
        "\n",
        "def train(epoch, loss_vector=None, log_interval=200):\n",
        "  # Set model to training mode\n",
        "  model.train()\n",
        "\n",
        "  # Loop over each batch from the training set\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    # Copy data to GPU if needed\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # Zero gradient buffers\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(b_input_ids, token_type_ids=None,\n",
        "                    attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    loss = outputs[0]\n",
        "    if loss_vector is not None:\n",
        "        loss_vector.append(loss.item())\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    if step % log_interval == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, step * len(b_input_ids),\n",
        "                len(train_dataloader.dataset),\n",
        "                100. * step / len(train_dataloader), loss))\n",
        "\n",
        "def evaluate(loader):\n",
        "  model.eval()\n",
        "\n",
        "  n_correct, n_all = 0, 0\n",
        "\n",
        "  for batch in loader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "      logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "\n",
        "    labels = b_labels.to('cpu').numpy()\n",
        "    n_correct += np.sum(predictions == labels)\n",
        "    n_all += len(labels)\n",
        "\n",
        "  print('Accuracy: [{}/{}] {:.4f}\\n'.format(n_correct,\n",
        "                                            n_all,\n",
        "                                            n_correct/n_all))\n",
        "\n",
        "# Now we are ready to train our model using the train()\n",
        "# function. After each epoch, we evaluate the model using the\n",
        "# validation set and evaluate().\n",
        "\n",
        "train_lossv = []\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(epoch, train_lossv)\n",
        "    print('\\nValidation set:')\n",
        "    evaluate(validation_dataloader)\n",
        "\n",
        "# ## Inference\n",
        "#\n",
        "# For a better measure of the quality of the model, let's see the\n",
        "# model accuracy for the test messages.\n",
        "\n",
        "print('Test set:')\n",
        "evaluate(test_dataloader)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/2702 (0%)]\tLoss: 3.016967\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [234/301] 0.7774\n",
            "\n",
            "Train Epoch: 2 [0/2702 (0%)]\tLoss: 0.647195\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [174/301] 0.5781\n",
            "\n",
            "Train Epoch: 3 [0/2702 (0%)]\tLoss: 0.713558\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [250/301] 0.8306\n",
            "\n",
            "Train Epoch: 4 [0/2702 (0%)]\tLoss: 0.505990\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [253/301] 0.8405\n",
            "\n",
            "Train Epoch: 5 [0/2702 (0%)]\tLoss: 0.118088\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [249/301] 0.8272\n",
            "\n",
            "Train Epoch: 6 [0/2702 (0%)]\tLoss: 0.038239\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [254/301] 0.8439\n",
            "\n",
            "Train Epoch: 7 [0/2702 (0%)]\tLoss: 0.023799\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [248/301] 0.8239\n",
            "\n",
            "Train Epoch: 8 [0/2702 (0%)]\tLoss: 0.054967\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [242/301] 0.8040\n",
            "\n",
            "Train Epoch: 9 [0/2702 (0%)]\tLoss: 0.010712\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [248/301] 0.8239\n",
            "\n",
            "Train Epoch: 10 [0/2702 (0%)]\tLoss: 0.219685\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [246/301] 0.8173\n",
            "\n",
            "Train Epoch: 11 [0/2702 (0%)]\tLoss: 0.006934\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [244/301] 0.8106\n",
            "\n",
            "Train Epoch: 12 [0/2702 (0%)]\tLoss: 0.005357\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [240/301] 0.7973\n",
            "\n",
            "Train Epoch: 13 [0/2702 (0%)]\tLoss: 0.005950\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [241/301] 0.8007\n",
            "\n",
            "Train Epoch: 14 [0/2702 (0%)]\tLoss: 0.005131\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [242/301] 0.8040\n",
            "\n",
            "Train Epoch: 15 [0/2702 (0%)]\tLoss: 0.004831\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [243/301] 0.8073\n",
            "\n",
            "Train Epoch: 16 [0/2702 (0%)]\tLoss: 0.004211\n",
            "\n",
            "Validation set:\n",
            "Accuracy: [242/301] 0.8040\n",
            "\n",
            "Test set:\n",
            "Accuracy: [3279/4000] 0.8197\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}